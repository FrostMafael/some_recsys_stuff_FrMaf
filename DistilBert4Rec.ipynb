{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "877a9e8b-e722-41d8-ac54-66e3407926a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.amp import GradScaler, autocast\n",
    "\n",
    "from transformers import DistilBertModel\n",
    "\n",
    "import faiss\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*nested tensors.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e69ca478-ad41-48ed-9fdc-523737ccfa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(r\"D:\\movies_dataset\\movies.csv\")\n",
    "ratings = pd.read_csv(r\"D:\\movies_dataset\\filtered_ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faae758b-fc81-4601-9f34-70df9e21316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_to_idx = {movie_id: idx + 2 for idx, movie_id in enumerate(movies['movieId'])}\n",
    "idx_to_movie = {idx + 2: movie_id for idx, movie_id in enumerate(movies['movieId'])}\n",
    "\n",
    "movie_to_idx['[PAD]'] = 0\n",
    "idx_to_movie[0] = '[PAD]'\n",
    "\n",
    "movie_to_idx['[MASK]'] = 1\n",
    "idx_to_movie[1] = '[MASK]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53855b60-af66-4c29-90a0-ec54dfb445ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sequences = ratings.groupby('userId', sort=True)['movieId'].apply(list).reset_index()\n",
    "user_sequences.columns = ['userId', 'sequence']\n",
    "\n",
    "user_sequences = user_sequences[user_sequences['sequence'].apply(len) > 1]\n",
    "\n",
    "user_sequences.loc[:, 'indexed_sequence'] = user_sequences['sequence'].apply(lambda seq: [movie_to_idx[movie_id] for movie_id in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1b3482-6257-4918-b007-cced640fb75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_examples(sequences, mask_token_id = 1, pad_token_id = 0, mask_prob = 0.1, num_mask = 5):\n",
    "    train_data = []\n",
    "    for seq in sequences:\n",
    "        for _ in range(num_mask):\n",
    "            input_seq = seq.copy()\n",
    "            target_seq = [pad_token_id] * len(seq)\n",
    "            mask_positions = []\n",
    "            for i in range(len(seq)):\n",
    "                if np.random.rand() < mask_prob and seq[i] != mask_token_id:\n",
    "                    target_seq[i] = seq[i]\n",
    "                    input_seq[i] = mask_token_id\n",
    "                    mask_positions.append(i)\n",
    "            if mask_positions:\n",
    "                train_data.append((input_seq, target_seq, mask_positions))\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cadab15a-66d4-4359-894e-b78fc5206b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_sequences, val_user_sequences = train_test_split(\n",
    "    user_sequences, test_size = 0.1, random_state = 42\n",
    ")\n",
    "\n",
    "train_user_sequences_4_examples = train_user_sequences['indexed_sequence'].tolist()\n",
    "training_examples = create_training_examples(train_user_sequences_4_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14e1f11b-d791-491e-86ba-fb279138e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4RecDataset(Dataset):\n",
    "    def __init__(self, training_examples, max_length = 10):\n",
    "        self.examples = training_examples\n",
    "        self.max_length = max_length\n",
    "        self.pad_token_id = 0\n",
    "        self.mask_token_id = 1\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_seq, target_seq, mask_positions = self.examples[idx]\n",
    "\n",
    "        if len(input_seq) < self.max_length:\n",
    "            pad_length = self.max_length - len(input_seq)\n",
    "            input_seq.extend([self.pad_token_id] * pad_length)\n",
    "            target_seq.extend([self.pad_token_id] * pad_length)\n",
    "\n",
    "        attention_mask = [1 if x != self.pad_token_id else 0 for x in input_seq]\n",
    "        labels_mask = [1 if i in mask_positions else 0 for i in range(len(target_seq))]\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_seq, dtype=torch.long),\n",
    "            'target_ids': torch.tensor(target_seq, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'labels_mask': torch.tensor(labels_mask, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f01ed3ea-c0bd-4b44-937f-bff68f34644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT4RecValidationDataset(Dataset):\n",
    "    def __init__(self, user_sequences_df, max_length = 10):\n",
    "        self.user_sequences = user_sequences_df.reset_index(drop = True)\n",
    "        self.max_length = max_length\n",
    "        self.pad_token_id = 0\n",
    "        self.mask_token_id = 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.user_sequences.loc[idx]\n",
    "        indexed_seq = row['indexed_sequence']\n",
    "\n",
    "        input_seq_indexed = indexed_seq[:-1]\n",
    "        target_movie_id = indexed_seq[-1]\n",
    "\n",
    "        input_seq_indexed = input_seq_indexed + [self.mask_token_id]\n",
    "        mask_position = len(input_seq_indexed) - 1\n",
    "\n",
    "        if len(input_seq_indexed) < self.max_length:\n",
    "            pad_length = self.max_length - len(input_seq_indexed)\n",
    "            input_seq_indexed.extend([self.pad_token_id] * pad_length)\n",
    "\n",
    "        attention_mask = [1 if x != self.pad_token_id else 0 for x in input_seq_indexed]\n",
    "        \n",
    "        labels_mask = [0] * self.max_length\n",
    "        labels_mask[mask_position] = 1\n",
    "\n",
    "        target_seq = [self.pad_token_id] * self.max_length\n",
    "        target_seq[mask_position] = target_movie_id\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_seq_indexed, dtype=torch.long),\n",
    "            'target_ids': torch.tensor(target_seq, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'labels_mask': torch.tensor(labels_mask, dtype=torch.long),\n",
    "            'true_movie_id': target_movie_id\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aa1d30b-03ff-47c8-a1bf-143ccf2678fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BERT4RecDataset(training_examples)\n",
    "dataloader = DataLoader(dataset, batch_size = 64, shuffle = True)\n",
    "val_dataset = BERT4RecValidationDataset(val_user_sequences)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = 64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4d6fce9-7fdd-40cb-99ba-0d9199f2daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_score(y_true, y_pred, k = 10):\n",
    "    order = np.argsort(y_pred)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "def ndcg_score(y_true, y_pred, k = 10):\n",
    "    best = dcg_score(y_true, y_true, k)\n",
    "    if best == 0:\n",
    "        return 0.0\n",
    "    actual = dcg_score(y_true, y_pred, k)\n",
    "    return actual / best\n",
    "\n",
    "def ndcg_at_k_batch(y_true_batch, y_pred_batch, k = 10):\n",
    "    scores = []\n",
    "    for y_true, y_pred in zip(y_true_batch, y_pred_batch):\n",
    "        if not y_true or not y_pred:\n",
    "             scores.append(0.0)\n",
    "             continue\n",
    "\n",
    "        relevance = [1 if movie_id in y_true else 0 for movie_id in y_pred[:k]]\n",
    "        count_relevant = sum(relevance)\n",
    "        ideal_relevance = [1] * min(count_relevant, k) + [0] * (k - min(count_relevant, k))\n",
    "\n",
    "        y_pred_actual = np.arange(k, 0, -1)\n",
    "        actual_dcg = dcg_score(relevance, y_pred_actual, k)\n",
    "\n",
    "        best_dcg = dcg_score(ideal_relevance, ideal_relevance, k)\n",
    "\n",
    "        scores.append(actual_dcg / best_dcg if best_dcg != 0 else 0.0)\n",
    "\n",
    "    return np.mean(scores) if scores else 0.0\n",
    "\n",
    "\n",
    "def recall_at_k_batch(y_true_batch, y_pred_batch, k = 10):\n",
    "    recalls = []\n",
    "    for y_true, y_pred in zip(y_true_batch, y_pred_batch):\n",
    "        if len(y_true) == 0:\n",
    "            recalls.append(1.0)\n",
    "            continue\n",
    "        y_pred_k = set(y_pred[:k])\n",
    "        y_true_set = set(y_true)\n",
    "        if len(y_true_set) == 0:\n",
    "            recalls.append(1.0)\n",
    "            continue\n",
    "        hits = len(y_true_set & y_pred_k)\n",
    "        recalls.append(hits / len(y_true_set))\n",
    "    return np.mean(recalls) if recalls else 0.0\n",
    "\n",
    "def precision_at_k_batch(y_true_batch, y_pred_batch, k = 10):\n",
    "    precisions = []\n",
    "    for y_true, y_pred in zip(y_true_batch, y_pred_batch):\n",
    "        y_pred_k = set(y_pred[:k])\n",
    "        y_true_set = set(y_true)\n",
    "        if len(y_pred_k) == 0:\n",
    "            precisions.append(1.0)\n",
    "            continue\n",
    "        hits = len(y_true_set & y_pred_k)\n",
    "        precisions.append(hits / len(y_pred_k))\n",
    "    return np.mean(precisions) if precisions else 0.0\n",
    "\n",
    "def hit_rate_at_k_batch(y_true_batch, y_pred_batch, k = 10):\n",
    "    hits = 0\n",
    "    total = len(y_true_batch)\n",
    "    for y_true, y_pred in zip(y_true_batch, y_pred_batch):\n",
    "        y_pred_k = set(y_pred[:k])\n",
    "        y_true_set = set(y_true)\n",
    "        if y_true_set & y_pred_k:\n",
    "            hits += 1\n",
    "    return hits / total if total > 0 else 0.0\n",
    "\n",
    "def average_precision_at_k(y_true, y_pred, k = 10):\n",
    "    if len(y_true) == 0:\n",
    "        return 0.0\n",
    "    y_pred_k = y_pred[:k]\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    for i, p in enumerate(y_pred_k):\n",
    "        if p in y_true and p not in y_pred_k[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "    if num_hits == 0:\n",
    "        return 0.0\n",
    "    return score / min(len(y_true), k)\n",
    "\n",
    "def map_at_k_batch(y_true_batch, y_pred_batch, k = 10):\n",
    "    aps = []\n",
    "    for y_true, y_pred in zip(y_true_batch, y_pred_batch):\n",
    "        ap = average_precision_at_k(y_true, y_pred, k)\n",
    "        aps.append(ap)\n",
    "    return np.mean(aps) if aps else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82aa5e07-ca6e-4691-9439-64fd7ce6a9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_dataloader, device, k = 10):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    all_y_true_movie_ids = []\n",
    "    all_y_pred_movie_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader, desc = \"Validation\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            target_ids = batch['target_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels_mask = batch['labels_mask'].to(device)\n",
    "\n",
    "            outputs = model(input_ids = input_ids, attention_mask = attention_mask)\n",
    "\n",
    "            loss = sampled_softmax_loss(\n",
    "                outputs,\n",
    "                target_ids,\n",
    "                num_samples = num_negative_samples,\n",
    "                vocab_size = len(movie_to_idx)\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "            batch_size, seq_length, vocab_size = outputs.shape\n",
    "            mask_positions = torch.where(labels_mask == 1)\n",
    "            masked_logits = outputs[mask_positions]\n",
    "\n",
    "            top_k_logits, top_k_indices = torch.topk(masked_logits, k, dim = 1, largest = True, sorted = True)\n",
    "\n",
    "            mask_token_idx = movie_to_idx['[MASK]']\n",
    "            top_k_indices_filtered = torch.where(top_k_indices == mask_token_idx, torch.tensor(0, device = top_k_indices.device), top_k_indices)\n",
    "\n",
    "            pred_movie_ids = []\n",
    "            for i in range(top_k_indices_filtered.shape[0]):\n",
    "                pred_ids_for_item = []\n",
    "                for idx in top_k_indices_filtered[i]:\n",
    "                    movie_id = idx_to_movie.get(idx.item(), 0)\n",
    "                    if movie_id != 0 and movie_id != '[PAD]':\n",
    "                        pred_ids_for_item.append(movie_id)\n",
    "                pred_movie_ids.append(pred_ids_for_item)\n",
    "\n",
    "            true_movie_ids_for_masks = target_ids[mask_positions].cpu().numpy()\n",
    "            true_movie_ids_converted = [idx_to_movie.get(idx, 0) for idx in true_movie_ids_for_masks]\n",
    "\n",
    "            y_true_batch = [[true_id] for true_id in true_movie_ids_converted]\n",
    "            y_pred_batch = pred_movie_ids\n",
    "\n",
    "            all_y_true_movie_ids.extend(y_true_batch)\n",
    "            all_y_pred_movie_ids.extend(y_pred_batch)\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "\n",
    "    recall_at_k = recall_at_k_batch(all_y_true_movie_ids, all_y_pred_movie_ids, k = k)\n",
    "    precision_at_k = precision_at_k_batch(all_y_true_movie_ids, all_y_pred_movie_ids, k = k)\n",
    "    map_at_k = map_at_k_batch(all_y_true_movie_ids, all_y_pred_movie_ids, k = k)\n",
    "    ndcg_at_k = ndcg_at_k_batch(all_y_true_movie_ids, all_y_pred_movie_ids, k = k)\n",
    "    hr_at_k = hit_rate_at_k_batch(all_y_true_movie_ids, all_y_pred_movie_ids, k = k)\n",
    "\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Recall@{k}: {recall_at_k:.4f}\")\n",
    "    print(f\"Precision@{k}: {precision_at_k:.4f}\")\n",
    "    print(f\"MAP@{k}: {map_at_k:.4f}\")\n",
    "    print(f\"NDCG@{k}: {ndcg_at_k:.4f}\")\n",
    "    print(f\"HR@{k}: {hr_at_k:.4f}\")\n",
    "\n",
    "    return avg_loss, recall_at_k, precision_at_k, map_at_k, ndcg_at_k, hr_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0ac205a-9317-467d-b68c-ea3a475eb2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "distil_bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").eval()\n",
    "\n",
    "for param in distil_bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a887cb15-07f7-4a1b-9ea1-d85c8a0a3a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76bcdc91-23ff-4840-9abc-2e4a34763f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert4Rec(nn.Module):\n",
    "    def __init__(self, distil_bert, nhead, dim_feedforward, num_layers, movie_len, max_len = 10, reduced_dim = 128):\n",
    "        super().__init__()\n",
    "        self.max_len = max_len\n",
    "        self.reduced_dim = reduced_dim\n",
    "        self.movie_len = movie_len\n",
    "\n",
    "        self.distil_bert = distil_bert\n",
    "\n",
    "        self.movie_adapter = nn.Embedding(movie_len, 768, padding_idx = 0)\n",
    "\n",
    "        self.distilbert_to_reduced = nn.Linear(768, reduced_dim)\n",
    "\n",
    "        self.position_embeddings = nn.Embedding(max_len, reduced_dim)\n",
    "\n",
    "        self.embedding_layer_norm = nn.LayerNorm(reduced_dim)\n",
    "        self.embedding_dropout = nn.Dropout(0.1)\n",
    "\n",
    "        encoder_layers = TransformerEncoderLayer(\n",
    "            reduced_dim,\n",
    "            nhead,\n",
    "            dim_feedforward,\n",
    "            dropout = 0.1,\n",
    "            activation = 'gelu',\n",
    "            batch_first = True\n",
    "        )\n",
    "        self.transformer = TransformerEncoder(encoder_layers, num_layers)\n",
    "\n",
    "        self.prediction_head = nn.Linear(reduced_dim, self.movie_len)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        batch_size, seq_length = input_ids.shape\n",
    "\n",
    "        movie_embeddings = self.movie_adapter(input_ids)  # [batch_size, seq_length, 768]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            distilbert_output = self.distil_bert(\n",
    "                inputs_embeds = movie_embeddings,\n",
    "                attention_mask = attention_mask\n",
    "            )\n",
    "            token_embeddings = distilbert_output.last_hidden_state  # [batch_size, seq_length, 768]\n",
    "\n",
    "        token_embeddings = self.distilbert_to_reduced(token_embeddings)  # [batch_size, seq_length, reduced_dim]\n",
    "\n",
    "        position_ids = torch.arange(seq_length, device = input_ids.device).unsqueeze(0).expand(batch_size, -1)\n",
    "        position_embeddings = self.position_embeddings(position_ids)  # [batch_size, seq_length, reduced_dim]\n",
    "\n",
    "        hidden_states = token_embeddings + position_embeddings\n",
    "        hidden_states = self.embedding_layer_norm(hidden_states)\n",
    "        hidden_states = self.embedding_dropout(hidden_states)\n",
    "\n",
    "        transformer_output = self.transformer(\n",
    "            hidden_states,\n",
    "            src_key_padding_mask = (attention_mask == 0)\n",
    "        )\n",
    "\n",
    "        logits = self.prediction_head(transformer_output)  # [batch_size, seq_length, movie_len]\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def get_movie_embeddings(self):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            movie_indices = torch.arange(2, self.movie_len, device=device)\n",
    "            movie_embeddings = self.movie_adapter(movie_indices)  # [num_movies, 768]\n",
    "            reduced_embeddings = self.distilbert_to_reduced(movie_embeddings)  # [num_movies, reduced_dim]\n",
    "            \n",
    "            return reduced_embeddings.cpu().numpy(), movie_indices.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47a19385-ec14-4043-9e49-a26df5f14f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Bert4Rec(\n",
    "    distil_bert, \n",
    "    nhead = 8,\n",
    "    dim_feedforward = 512,\n",
    "    num_layers = 3,\n",
    "    movie_len = len(movie_to_idx),\n",
    "    reduced_dim = 128\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6920fee-03ad-42ee-afbf-b7162216197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampled_softmax_loss(logits, targets, num_samples, vocab_size, padding_idx = 0, mask_idx = 1):\n",
    "\n",
    "    mask = (targets != padding_idx)\n",
    "    masked_logits = logits[mask]  # [num_masked, vocab_size]\n",
    "    masked_targets = targets[mask]  # [num_masked]\n",
    "    \n",
    "    batch_size = masked_logits.size(0)\n",
    "    \n",
    "    weights = torch.ones(vocab_size, device = logits.device)\n",
    "    weights[padding_idx] = 0\n",
    "    weights[mask_idx] = 0\n",
    "\n",
    "    neg_samples = torch.multinomial(\n",
    "        weights, \n",
    "        batch_size * num_samples, \n",
    "        replacement = True\n",
    "    ).view(batch_size, num_samples)\n",
    "    \n",
    "    mask = (neg_samples == masked_targets.unsqueeze(1))\n",
    "\n",
    "    if mask.any():\n",
    "        total_replacements = mask.sum().item()\n",
    "        replacement = torch.multinomial(weights, total_replacements, replacement = True)\n",
    "\n",
    "        neg_samples[mask] = replacement\n",
    "    \n",
    "    all_indices = torch.cat([masked_targets.unsqueeze(1), neg_samples], dim = 1)  # [batch_size, num_samples + 1]\n",
    "\n",
    "    selected_logits = torch.gather(masked_logits, 1, all_indices)\n",
    "\n",
    "    targets_for_loss = torch.zeros(batch_size, dtype=torch.long, device = logits.device)\n",
    "\n",
    "    loss = F.cross_entropy(selected_logits, targets_for_loss)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98343d6d-c2f9-4729-b501-ce4909d7965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler(device.type)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 3e-4)\n",
    "\n",
    "num_negative_samples = 1000\n",
    "epochs = 10\n",
    "k_for_metrics = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f37395c2-87df-4c41-b03f-38b1bafea9ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8759/8759 [08:30<00:00, 17.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Avg Loss: 3.4281 | Total Loss: 30026.6668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 369/369 [00:28<00:00, 13.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.3967\n",
      "Recall@10: 0.0848\n",
      "Precision@10: 0.0085\n",
      "MAP@10: 0.0295\n",
      "NDCG@10: 0.0422\n",
      "HR@10: 0.0848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8759/8759 [08:34<00:00, 17.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Avg Loss: 3.1724 | Total Loss: 27787.4799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 369/369 [00:28<00:00, 12.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.3341\n",
      "Recall@10: 0.0941\n",
      "Precision@10: 0.0094\n",
      "MAP@10: 0.0346\n",
      "NDCG@10: 0.0483\n",
      "HR@10: 0.0941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8759/8759 [09:35<00:00, 15.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Avg Loss: 3.0827 | Total Loss: 27001.1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 369/369 [00:31<00:00, 11.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.2646\n",
      "Recall@10: 0.1001\n",
      "Precision@10: 0.0100\n",
      "MAP@10: 0.0369\n",
      "NDCG@10: 0.0515\n",
      "HR@10: 0.1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8759/8759 [09:48<00:00, 14.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Avg Loss: 3.0145 | Total Loss: 26404.2613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 369/369 [00:32<00:00, 11.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.2548\n",
      "Recall@10: 0.1028\n",
      "Precision@10: 0.0103\n",
      "MAP@10: 0.0387\n",
      "NDCG@10: 0.0535\n",
      "HR@10: 0.1028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8759/8759 [09:46<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Avg Loss: 2.9557 | Total Loss: 25889.1025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 369/369 [00:31<00:00, 11.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.2222\n",
      "Recall@10: 0.1078\n",
      "Precision@10: 0.0108\n",
      "MAP@10: 0.0418\n",
      "NDCG@10: 0.0570\n",
      "HR@10: 0.1078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8759/8759 [09:32<00:00, 15.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Avg Loss: 2.9071 | Total Loss: 25463.5317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 369/369 [00:28<00:00, 13.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.1971\n",
      "Recall@10: 0.1129\n",
      "Precision@10: 0.0113\n",
      "MAP@10: 0.0436\n",
      "NDCG@10: 0.0597\n",
      "HR@10: 0.1129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8759/8759 [08:27<00:00, 17.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Avg Loss: 2.8605 | Total Loss: 25055.2490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 369/369 [00:27<00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.2026\n",
      "Recall@10: 0.1128\n",
      "Precision@10: 0.0113\n",
      "MAP@10: 0.0437\n",
      "NDCG@10: 0.0597\n",
      "HR@10: 0.1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8759/8759 [09:05<00:00, 16.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Avg Loss: 2.8201 | Total Loss: 24701.2040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 369/369 [00:30<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.1825\n",
      "Recall@10: 0.1174\n",
      "Precision@10: 0.0117\n",
      "MAP@10: 0.0451\n",
      "NDCG@10: 0.0618\n",
      "HR@10: 0.1174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8759/8759 [09:03<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Avg Loss: 2.7834 | Total Loss: 24379.4392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 369/369 [00:29<00:00, 12.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.1644\n",
      "Recall@10: 0.1172\n",
      "Precision@10: 0.0117\n",
      "MAP@10: 0.0457\n",
      "NDCG@10: 0.0623\n",
      "HR@10: 0.1172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8759/8759 [08:26<00:00, 17.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Avg Loss: 2.7472 | Total Loss: 24063.1060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 369/369 [00:27<00:00, 13.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.1664\n",
      "Recall@10: 0.1202\n",
      "Precision@10: 0.0120\n",
      "MAP@10: 0.0452\n",
      "NDCG@10: 0.0625\n",
      "HR@10: 0.1202\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    for batch in tqdm(dataloader, desc = \"Training\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        target_ids = batch['target_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels_mask = batch['labels_mask'].to(device)\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast(device.type):\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            loss = sampled_softmax_loss(\n",
    "                outputs,\n",
    "                target_ids,\n",
    "                num_samples = num_negative_samples,\n",
    "                vocab_size = len(movie_to_idx),\n",
    "            )\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Epoch {epoch+1} | Avg Loss: {avg_loss:.4f} | Total Loss: {total_loss:.4f}\")\n",
    "    \n",
    "    val_loss, recall_k, precision_k, map_k, ndcg_k, hr_k = validate(model, val_dataloader, device, k=k_for_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "900fe244-df3c-4df6-8895-fc1050268189",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaissRecommender:\n",
    "    def __init__(self, model, device, movie_to_idx, idx_to_movie):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.movie_to_idx = movie_to_idx\n",
    "        self.idx_to_movie = idx_to_movie\n",
    "        self.index = None\n",
    "        self.movie_vectors = None\n",
    "        self.movie_indices = None\n",
    "\n",
    "    def build_index(self):\n",
    "        movie_embeddings, movie_indices = self.model.get_movie_embeddings()\n",
    "        self.movie_vectors = movie_embeddings\n",
    "        self.movie_indices = movie_indices\n",
    "        faiss.normalize_L2(movie_embeddings)\n",
    "\n",
    "        # HNSW\n",
    "        dim = movie_embeddings.shape[1]\n",
    "        self.index = faiss.IndexHNSWFlat(dim, 32)\n",
    "        self.index.hnsw.efConstruction = 40\n",
    "        self.index.hnsw.efSearch = 16\n",
    "\n",
    "        self.index.add(movie_embeddings)\n",
    "\n",
    "    def get_recommendations(self, watched_movies, k=10, exclude_watched = True):\n",
    "        watched_indices = [\n",
    "            self.movie_to_idx[mid] for mid in watched_movies if mid in self.movie_to_idx\n",
    "        ]\n",
    "\n",
    "        if not watched_indices:\n",
    "            return []\n",
    "\n",
    "        valid_indices = [idx - 2 for idx in watched_indices if idx >= 2]\n",
    "        watched_vectors = self.movie_vectors[valid_indices]\n",
    "        query_vector = np.mean(watched_vectors, axis=0, keepdims=True)\n",
    "        faiss.normalize_L2(query_vector)\n",
    "\n",
    "        total_k = k + len(watched_indices) if exclude_watched else k\n",
    "        scores, indices = self.index.search(query_vector, total_k)\n",
    "\n",
    "        recommendations = []\n",
    "        watched_set = set(watched_movies) if exclude_watched else set()\n",
    "\n",
    "        for idx, score in zip(indices[0], scores[0]):\n",
    "            if idx >= len(self.movie_indices):\n",
    "                continue\n",
    "\n",
    "            movie_idx = self.movie_indices[idx]\n",
    "            movie_id = self.idx_to_movie[movie_idx]\n",
    "\n",
    "            if exclude_watched and movie_id in watched_set:\n",
    "                continue\n",
    "\n",
    "            recommendations.append((movie_id, float(score)))\n",
    "\n",
    "            if len(recommendations) == k:\n",
    "                break\n",
    "\n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9d3679c-1a45-4b85-943c-02567ea2a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_recommender = FaissRecommender(model, device, movie_to_idx, idx_to_movie)\n",
    "faiss_recommender.build_index()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bef4bba5-f669-4955-a69c-c1b01ed7e7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History: ['Money Train (1995)', 'Dangerous Minds (1995)']:\n",
      "1. Film: Akaton mies (1983) (score: 0.9087)\n",
      "2. Film: The Black Shield Of Falworth (1954) (score: 0.9255)\n",
      "3. Film: Baadasssss! (How to Get the Man's Foot Outta Your Ass) (2003) (score: 0.9289)\n",
      "4. Film: For a Cop's Hide (1981) (score: 0.9362)\n",
      "5. Film: Bullets or Ballots (1936) (score: 0.9477)\n"
     ]
    }
   ],
   "source": [
    "k = 5 \n",
    "user_history = [20, 31]\n",
    "recommendations = faiss_recommender.get_recommendations(user_history, k = k)\n",
    "titles = movies[movies['movieId'].isin(user_history)]['title'].tolist()\n",
    "\n",
    "print(f\"History: {titles}:\")\n",
    "for i, (movie_id, score) in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. Film: {movies['title'][movies['movieId'] == movie_id].item()} (score: {score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709feff7-c346-4231-8ff0-f63b2cf9ca2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
